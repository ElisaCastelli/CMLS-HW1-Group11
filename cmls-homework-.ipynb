{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CMLS - Homework 1 - Assignment 4","metadata":{}},{"cell_type":"markdown","source":"Useful links:\n* Reference [paper](http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_urbansound_acmmm14.pdf)\n* [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html) in SKLearn\n* [Urbansound8K](https://urbansounddataset.weebly.com/urbansound8k.html) documentation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa\nimport os\nimport scipy as sp\n%matplotlib inline\n\nfrom tqdm import tqdm\nimport pickle # to save the object as a file\nimport sklearn\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\nimport matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure\nimport IPython.display as ipd\nfrom sklearn.mixture import BayesianGaussianMixture\nimport scipy.stats\nimport seaborn as sns\nimport csv\nfrom tqdm import tqdm   #to monitor loops during computation","metadata":{"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"n_mfcc = 25\n\nclass Sound:\n    \n    def __init__(self, path, slice_file_name, fold, classID, class_name, startTime, endTime):\n        self.slice_file_name = path +'/fold'+fold+'/'+slice_file_name\n        self.fold = fold\n        self.classID = int(classID)\n        self.class_name = class_name\n        self.startTime = startTime\n        self.endTime = endTime\n        self.features = None\n        self.mfcc = None\n        self.chroma = None\n        self.spec_con = None\n        \n    def extract_features(self):\n        audio, fs = librosa.load(self.slice_file_name, sr=None)\n        #audio = audio[0:4*fs]\n        mfcc = compute_mfcc(audio,fs, n_mfcc)\n        self.mfcc = np.mean(mfcc, axis=1)\n        #mfcc = librosa.feature.mfcc(y = audio, sr = fs, n_mfcc = n_mfcc)\n        chroma_matrix = librosa.feature.chroma_stft(audio, fs)\n        self.chroma = np.mean(chroma_matrix, axis=1)\n        spec_con = librosa.feature.spectral_contrast(y=audio, sr=fs, n_bands=3)\n        self.spec_con = spec_con.mean(axis=1)\n        self.features = np.concatenate((np.mean(mfcc, axis=1),np.std(mfcc, axis=1), np.mean(chroma_matrix, axis=1), chroma_matrix.std(axis=1), spec_con.mean(axis=1), spec_con.std(axis=1)),axis =0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_mfcc(audio, fs, n_mfcc):\n    # Compute the spectrogram of the audio signal \n    X = np.abs(librosa.stft(\n    audio,\n    window='hamming',\n    n_fft = 1024,\n    hop_length = 512,\n    ))\n    \n    # Find the weights of the mel filters\n    mel = librosa.filters.mel(\n        sr = fs,\n        n_fft = 1024,\n        n_mels = 40,\n        fmin = 0,\n        fmax = 22050\n    )\n    \n    # Apply the filters to spectrogram\n    melspectrogram = np.dot(mel, X) \n    log_melspectrogram = np.log10(melspectrogram + 1e-16)\n    \n    # Apply the DCT to log melspectrogram to obtain the coefficients\n    mfcc = sp.fftpack.dct(log_melspectrogram, axis=0, norm='ortho')[1:n_mfcc + 1]\n    \n    return mfcc\n","metadata":{"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def compute_training_set(test_folder):\n    train_files = [s for s in soundList if s.fold!=test_folder]\n    n_train_samples = len(train_files)\n    train_features = np.zeros((n_train_samples, 82))\n    train_labels = []\n    \n    for i,f in enumerate(train_files):\n        train_features[i,:] = train_files[i].features\n        train_labels.append(train_files[i].classID)\n        \n    return [train_features, train_labels]\n\ndef compute_test_set(test_folder):\n    test_files = [s for s in soundList if s.fold==test_folder]\n    n_test_samples = len(test_files)\n    test_features = np.zeros((n_test_samples, 82))\n    test_labels = []\n    \n    for i,f in enumerate(test_files):\n        test_features[i,:] = test_files[i].features\n        test_labels.append(test_files[i].classID)\n    \n    return [test_features, test_labels]\n","metadata":{"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"Read CSV & extract features:","metadata":{}},{"cell_type":"code","source":"classes = ['air_conditioner',\n           'car_horn',\n           'children_playing',\n           'dog_bark',\n           'drilling',\n           'engine_idling',\n           'gun_shot',\n           'jackhammer',\n           'siren',\n           'street_music'\n          ]\n\nclassesID = {\n    'air_conditioner': 0,\n    'car_horn': 1,\n    'children_playing' : 2,\n    'dog_bark': 3,\n    'drilling': 4,\n    'engine_idling':5,\n    'gun_shot': 6,\n    'jackhammer': 7,\n    'siren': 8,\n    'street_music': 9\n}","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"path = '../input/urbansound8k/UrbanSound8K.csv'\nsoundList = []\nwith open(path, newline='') as soundcsv:\n        reader = csv.DictReader(soundcsv)\n        totalrows = 8732 #sum(1 for row in reader) # ma non so perch√® non funziona\n        for row in tqdm(reader, total=totalrows):\n        #for row in reader: #old\n            s = Sound('../input/urbansound8k', row['slice_file_name'], row['fold'], row['classID'], row['class'], row['start'], \n                      row['end'])\n            s.extract_features()\n            soundList.append(s)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save the featurese in a file for a faster loading","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n# datetime object containing current date and time\nnow = datetime.now()\ndt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\nwith open(\"./soundList_\" + dt_string + \".cmls\", \"wb\") as f:\n    pickle.dump(soundList, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the features\n","metadata":{}},{"cell_type":"code","source":"soundList = []\npath_to_load = '../input/cmls-homework/soundList_26_04_2021__14_18_12.cmls' #cambia path\nwith open(path_to_load, 'rb') as soundList_file: \n    soundList = pickle.load(soundList_file)\n    # After config_dictionary is read from file\n    # print(soundList)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature visualization","metadata":{}},{"cell_type":"code","source":"## visualization of features for one class\nfor c in classes:\n    if c == 'gun_shot':\n        mfcc = [s.mfcc for s in soundList if s.class_name==c]\n        mfcc = np.array(mfcc).transpose()\n        # Visualization\n        fig = plt.figure(figsize=(16, 6))\n        plt.subplot(1,2,1)\n        plt.imshow(mfcc, origin='lower', aspect='auto')\n        plt.xlabel('Training samples')\n        plt.ylabel('MFCC coefficients')\n        plt.title('MFCC (coefficients 0 to 25) for class {}'.format(c))\n        plt.colorbar()\n        plt.tight_layout()\n        ''''\n        mfcc_upper = mfcc[4:]\n        plt.subplot(1,2,2)\n        plt.imshow(mfcc_upper, origin='lower', aspect='auto')\n        plt.title('MFCC (coefficients 4 to 25) for class {}'.format(c))\n        plt.xlabel('Training samples')\n        plt.ylabel('MFCC coefficients')\n        plt.colorbar()\n        plt.tight_layout()\n        '''\n        \n        chroma = [s.chroma for s in soundList if s.class_name==c]\n        chroma = np.array(chroma).transpose()\n        # Visualization\n        fig = plt.figure(figsize=(16, 6))\n        plt.subplot(1,4,2)\n        plt.imshow(chroma, origin='lower', aspect='auto')\n        plt.xlabel('Training samples')\n        plt.ylabel('Chroma feature coefficients')\n        plt.title('Chroma feature for class {}'.format(c))\n        plt.colorbar()\n        plt.tight_layout()\n        \n        spec_con = [s.spec_con for s in soundList if s.class_name==c]\n        spec_con = np.array(spec_con).transpose()\n        # Visualization\n        fig = plt.figure(figsize=(16, 6))\n        plt.subplot(1,4,3)\n        plt.imshow(spec_con, origin='lower', aspect='auto')\n        plt.xlabel('Training samples')\n        plt.ylabel('Spectral constrast coefficients')\n        plt.title('Spectral contrast for class {}'.format(c))\n        plt.colorbar()\n        plt.tight_layout()\n        \n        \n        feat = [s.features for s in soundList if s.class_name==c]\n        feat = np.array(feat).transpose()\n        fig = plt.figure(figsize=(16, 6))\n        plt.subplot(1,4,4)\n        plt.imshow(feat, origin='lower', aspect='auto')\n        plt.xlabel('Training samples')\n        plt.ylabel('Total features coefficients')\n        plt.title('Total features for class {}'.format(c))\n        plt.colorbar()\n        plt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training with cross-validation (10 folds)","metadata":{}},{"cell_type":"code","source":"def compute_cm_multiclass(gt, predicted):   \n    classes = np.unique(gt)\n    #print(\"classes: \", classes)\n    \n    CM = np.zeros((len(classes), len(classes)))\n    \n    for i in np.arange(len(classes)):\n        pred_class = predicted[gt==i]\n        #print(\"pred_class\", pred_class)\n        \n        for j in np.arange(len(pred_class)):\n            CM[i, int(pred_class[j])] = CM[i, int(pred_class[j])] + 1 \n    return CM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nk = 10\n\n# Metrics\ncm_multiclass = np.zeros((len(classes), len(classes)))\naccuracy = []\n\nSVM_parameters = {\n    'C': 1,\n    'kernel': 'rbf',\n}\n\nmodel = sklearn.svm.SVC(**SVM_parameters, probability=True)\n\n\n## Main FOR cycle\nfor i in tqdm(np.arange(1,k+1)):\n    [X_train, y_train] = compute_training_set(str(i))\n    [X_test, y_test] = compute_test_set(str(i))\n    \n    ss = StandardScaler(copy=True)\n    X_train = ss.fit_transform(X_train)\n    X_test = ss.transform(X_test)\n    \n    # Train model\n    model.fit(X_train, y_train)\n    y_test_predicted = model.predict(X_test)\n    \n    cm_multiclass += compute_cm_multiclass(y_test, y_test_predicted)\n    accuracy.append(accuracy_score(y_test, y_test_predicted))\n\nprint(cm_multiclass)\n\n#Average accuracy\nprint(\"Accuracy: {}\".format([i * 100 for i in accuracy]))\nprint(\"Average accuracy: {}%\".format(np.mean(accuracy)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot confusion matrix using [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(10, 10));\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm_multiclass, display_labels=classes);\ndisp.plot(xticks_rotation='vertical', values_format='.1f', ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy per class\n\nCompute metrics (**accuracy** only):\n\\begin{equation}\nACC = \\frac{TP+TN}{TP+TN+FP+FN}\n\\end{equation}","metadata":{}},{"cell_type":"code","source":"def compute_class_accuracy(CM, myclassID):\n        TP = CM[myclassID, myclassID]\n        FP = CM[:, myclassID].sum() - TP\n        FN = CM[myclassID, :].sum() - TP\n        TN = CM.sum() - (FP + FN + TP)\n        \n        TP = TP.astype(float)\n        FP = FP.astype(float)\n        TN = TN.astype(float)\n        FN = FN.astype(float)\n        \n        class_acc = (TP + TN)/(TP + TN + FP + FN)\n        return class_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in classes:\n    classID = classesID[c]\n    classAcc = compute_class_accuracy(cm_multiclass, classID)\n    print(\"Accuracy for the class {0} is {1:.2f} % \\n \".format(c, classAcc*100))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}